<...>

Явно стоит попробовать:
* Segment anything (работает вроде просто потрясающе, я не знаю что там по скорости, но это просто топ), понятно что если ищем облака, а умеем отделать только небо от не неба, то можем внутри неба снова запустить сегментацию
	* Нужно понять формат работы segment anything и что он выдаёт, если просто куча классов, то нужно понять как выбирать из них небо
		* You can train or fine-tune SAM 2 on custom datasets of images, videos, or both. Please check the training [README](https://github.com/facebookresearch/sam2/blob/main/training/README.md) on how to get started
	* кажется требует некоторый промпт (тыкнуть в область, начиная с нее выделит сегмент), нужно от этого избавиться и иметь все сегменты или придумать предобработку чтоб знать куда тыкать в поисках неба
		* очевидное решение: какие то цветовые границы (учитывая всю цветовую гамму изображения понять в каких границах был бы средний цвет неба) [[РешениеЦветовыеГраницы]]
		* использовать готовый классификатор, причем он должен быть очень легким (возможно легче самому его обучить)
			*  [[РешениеКлассификатор]]
Если свой классификатор то нужно на чем то обучаться (CLIP): у него отличные эмбеддинги, плюс можно хранить и текстовое описание, если наделать кучу изображений и достать из них все сегменты, CLIP присвоит им описания небо или не небо, затем весь pipeline будет:
1. SegmentAnything достает все сегменты
	1. Это очень медленно, глобально мне нужно только отличать небо от неба, да и segmentanything достает все сегменты достаточно банально - просто кидает рандомно кучу точек в картинку. Главная трудность сейчас - разметить данные для классификатора
2. Классификация
	1. Пропускаем каждый из них через CLIP и достаем Embedding-и. На них обучаем классификатор
	2. Просто учим сеть (понять какую лучше архитектуру) на сегментах говорить небо или не небо
3. Profit

#### Нужно: 
1. Хранить все сегменты изображения
2. 
